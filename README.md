# ğŸ“š ë”¥ëŸ¬ë‹ ë…¼ë¬¸ì½ê¸° ìŠ¤í„°ë””

- ë§¤ì£¼ ë³¸ì¸ì´ ì½ê³ ì‹¶ì€ ë…¼ë¬¸ì„ í•˜ë‚˜ì”© ë¦¬ë·°í•˜ê³  ë‹¤ë¥¸ ì‚¬ëŒë“¤ ì•ì—ì„œ ë°œí‘œí•˜ëŠ” ìŠ¤í„°ë””ì…ë‹ˆë‹¤.
- ë°œí‘œëŠ” ë§¤ì£¼ ëª©ìš”ì¼ ì˜¤í›„ 8ì‹œì— [ë””ìŠ¤ì½”ë“œ](https://discord.gg/3EU4GXtG)ì—ì„œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.

### Image Enhancement (ì´ë¯¸ì§€ ê°œì„ )
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|HDRUNet: Single Image HDR Reconstruction with Denoising and Dequantization|[Link](https://arxiv.org/pdf/2105.13084)|[Link](https://dohyeon.tistory.com/96)|ìœ¤ë„í˜„|
|Replacing Mobile Camera ISP with a Single Deep Learning Model|[Link](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Ignatov_Replacing_Mobile_Camera_ISP_With_a_Single_Deep_Learning_Model_CVPRW_2020_paper.pdf)|[Link](https://dohyeon.tistory.com/103)|ìœ¤ë„í˜„|
|RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image|[Link](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.pdf)|[Link](https://dohyeon.tistory.com/104)|ìœ¤ë„í˜„|

### Object Detection & Segmentation (ê°ì²´ íƒì§€ & ë¶„í• )
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|DETRs with Collaborative Hybrid Assignments Training|[Link](https://openaccess.thecvf.com//content/ICCV2023/papers/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.pdf)|[Link](https://dohyeon.tistory.com/105)|ìœ¤ë„í˜„|

### Depth Estimation (ê¹Šì´ ì¸¡ì •)
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching|[Link](https://arxiv.org/pdf/2007.12140)|[Link](https://dohyeon.tistory.com/91)|ìœ¤ë„í˜„|
|UniDepth: Universal Monocular Metric Depth Estimation|[Link](https://arxiv.org/pdf/2403.18913)|[Link](https://dohyeon.tistory.com/110)|ìœ¤ë„í˜„|

### 3D Reconstruction (3ì°¨ì› ë³µì›)
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis|[Link](https://arxiv.org/abs/2003.08934)|[Link](https://dohyeon.tistory.com/92)|ìœ¤ë„í˜„|
|3D Gaussian Splatting for Real-Time Radiance Field Rendering|[Link](https://arxiv.org/pdf/2308.04079)|[Link](https://ripe-myrtle-c69.notion.site/3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering-a96a0b27b33046b481566301d96449fa?pvs=4)|ì´í•˜ì •|

### Autonomous Driving (ììœ¨ ì£¼í–‰)
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries|[Link](https://arxiv.org/pdf/2110.06922)|[Link](https://dohyeon.tistory.com/94)|ìœ¤ë„í˜„|
|Multi-Modal Fusion Transformer for End-to-End Autonomous Driving|[Link](https://arxiv.org/pdf/2104.09224)|[Link](https://ripe-myrtle-c69.notion.site/Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving-8398c1292035440a9afb4f1321533fc1?pvs=4)|ì´í•˜ì •|
|BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Birdâ€™s-Eye View Representation|[Link](https://arxiv.org/pdf/2205.13542)|[Link](https://medium.com/@lth7234/bev-fusion-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-059ebf6c23d8)|ì´íƒœí›ˆ|

### LLM & Multi-modal (ìì—°ì–´ì²˜ë¦¬ & ë©€í‹°ëª¨ë‹¬)
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|Visual Instruction Tuning|[Link](https://arxiv.org/pdf/2304.08485)|[Link](https://ripe-myrtle-c69.notion.site/Visual-Instruction-Tuning-47d50207618e49af8b208cd367eb6bf1?pvs=4)|ì´í•˜ì •|
|LLaMA: Open and Efficient Foundation Language Models|[Link](https://arxiv.org/pdf/2302.13971)|[Link](https://ripe-myrtle-c69.notion.site/LLaMA-Open-and-Efficient-Foundation-Language-Models-984b585ae63d450a82489f781339b93e?pvs=4)|ì´í•˜ì •|
|Text2Loc: 3D Point Cloud Localization from Natural Language|[Link](https://arxiv.org/pdf/2311.15977)|[Link](https://docs.google.com/presentation/d/1LekRr87Gu6Ealb8aZ4uac3q0ifQ9iFtw/edit?usp=sharing&ouid=102530899453259820171&rtpof=true&sd=true)|ì´í•˜ì •|

### Model Compression (ëª¨ë¸ ê²½ëŸ‰í™”)
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation|[Link](https://arxiv.org/pdf/2004.09602)|[Link](https://dohyeon.tistory.com/99)|ìœ¤ë„í˜„|

### Computer Graphics
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold|[Link](https://arxiv.org/pdf/2305.10973)|[Link](https://ripe-myrtle-c69.notion.site/Drag-Your-GAN-Interactive-Point-based-Manipulation-on-the-Generative-Image-Manifold-c94c214577654a98844de9d368421640?pvs=4)|ì´í•˜ì •|
|4D Gaussian Splatting for Real-Time Dynamic Scene Rendering|[Link](https://arxiv.org/pdf/2310.08528v2)|[Link](https://ripe-myrtle-c69.notion.site/4D-Gaussian-Splatting-for-Real-Time-Dynamic-Scene-Rendering-fe242863bf4a411d8cce5c5bd2d03658?pvs=4)|ì´í•˜ì •|

### etc (ê¸°íƒ€)
|Title|Original Paper Link|Paper Review|reviewer|
|------|---|---|---|
|DREAMFUSION: TEXT-TO-3D USING 2D DIFFUSION|[Link](https://arxiv.org/pdf/2209.14988)|[Link](https://ripe-myrtle-c69.notion.site/DREAMFUSION-TEXT-TO-3D-USING-2D-DIFFUSION-6fcf049f5ed94a45bcb2c0606329e027?pvs=4)|ì´í•˜ì •|
|PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation|[Link](https://arxiv.org/pdf/1612.00593)|[Link](https://docs.google.com/presentation/d/1PpHCc6Soce7L5RebuxaLdj0kdA9G9seTRJrd4LEVOcY/edit#slide=id.p)|ì´íƒœí›ˆ|
|Swin Transformer: Hierarchical Vision Transformer using Shifted Windows|[Link](https://arxiv.org/pdf/2103.14030)|[Link](https://medium.com/@lth7234/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-swin-transformer-hierarchical-vision-transformer-using-shifted-windows-bcb530509f4d)|ì´íƒœí›ˆ|
|Grounding Image Matching in 3D with MASt3R|[Link](https://arxiv.org/pdf/2406.09756)|[Link](https://ripe-myrtle-c69.notion.site/Grounding-Image-Matching-in-3D-with-MASt3R-89c57e70062545cea2bacc283d54751b?pvs=4)|ì´í•˜ì •|
|ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation|[Link](https://arxiv.org/pdf/2305.16213)|[Link](https://ripe-myrtle-c69.notion.site/ProlificDreamer-High-Fidelity-and-Diverse-Text-to-3D-Generation-with-Variational-Score-Distillation-412db25bbdb0490b910ecd0b8e3ccb65?pvs=4)|ì´í•˜ì •|
|FaceNet: A Unified Embedding for Face Recognition and Clustering|[Link](https://arxiv.org/abs/1503.03832)|[Link](https://dohyeon.tistory.com/111)|ìœ¤ë„í˜„|
|Tracking Persons-of-Interest via Unsupervised Representation Adaptation|[Link](https://arxiv.org/abs/1710.02139)|[Link](https://dohyeon.tistory.com/114)|ìœ¤ë„í˜„|

### âœ… ì•½ì†
- ë‹¤ìŒ ë°œí‘œìëŠ” ì¼ìš”ì¼ ë°¤ 23:59ê¹Œì§€ ë³¸ì¸ì´ ë¦¬ë·°í•  ë…¼ë¬¸ì„ [Issue](https://github.com/dohyeonYoon/Deep-Learning-Paper-Review/issues)ì— ë“±ë¡í•´ì£¼ì„¸ìš”.
- ë°œí‘œê°€ ëë‚˜ë©´ "**ë³¸ì¸ì˜ ê¹ƒí—ˆë¸Œ ë¸Œëœì¹˜**"ì—ì„œ ì»¤ë°‹í•œ ë’¤ ë‹¹ì¼ 23:59ê¹Œì§€ ë°œí‘œìë£Œì˜ [PR](https://github.com/dohyeonYoon/Deep-Learning-Paper-Review/pulls)ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

### ğŸ“‹ ì»¤ë°‹ê·œì¹™
```
1. ì €ì¥ì†Œ localë¡œ clone (ìµœì´ˆ 1ë²ˆë§Œ)
$ git clone https://github.com/dohyeonYoon/Deep-Learning-Paper-Review.git

2. ë¨¼ì € ë³¸ì¸ì˜ ë¡œì»¬ ë©”ì¸ ë¸Œëœì¹˜ë¥¼ ìµœì‹  ìƒíƒœë¡œ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤.
$ git checkout main #ë©”ì¸ ë¸Œëœì¹˜ë¡œ ì´ë™
$ git pull origin main #ì›ê²© ì €ì¥ì†Œì—ì„œ ìµœì‹  ë©”ì¸ ë¸Œëœì¹˜ ë‚´ìš© ë°›ì•„ì˜¤ê¸°
$ git checkout feature/ydh #ì‘ì—… ë¸Œëœì¹˜ë¡œ ì´ë™
$ git merge main #ë©”ì¸ ë¸Œëœì¹˜ ë‚´ìš©ì„ ì‘ì—… ë¸Œëœì¹˜ì— ë³‘í•©

3. readme fileì„ ìˆ˜ì •í•˜ê³  ë³¸ì¸ì˜ ë¸Œëœì¹˜ë¡œ ì»¤ë°‹
$ git add README.md
$ git commit -m "docs: ë…¼ë¬¸ë¦¬ë·° ì¶”ê°€, close #1" #ë³¸ì¸ì˜ ì´ìŠˆë¥¼ ì—°ë™í•˜ê³  PRì´ ë³‘í•©ë˜ë©´ ì´ìŠˆë‹«í˜
$ git push origin feature/ydh #ì‘ì—… ë¸Œëœì¹˜ì— í‘¸ì‹œ

4. ê¹ƒí—ˆë¸Œì—ì„œ PR ìƒì„±
```

### ğŸ‘¨ğŸ¼â€ğŸ’» Members

<table align="center">
  <tr height="35px">
    <td align="center" width="320px">
      <a> ìœ¤ë„í˜„ </a>
    </td>
    <td align="center" width="320px">
      <a> ì´í•˜ì • </a>
    </td>
    <td align="center" width="320px">
      <a> ì´íƒœí›ˆ </a>
    </td>
  </tr>
  <tr height="35px">
    <td align="center" width="320px">
      <a href="https://github.com/dohyeonYoon"><img src="https://github.com/dohyeonYoon.png" width="100"></a>
    </td>
    <td align="center" width="320px">
      <a href="https://github.com/SS-hj"><img src="https://github.com/SS-hj.png" width="100">
    </td>
    <td align="center" width="320px">
      <a href="https://github.com/taehunlee990803"><img src="https://github.com/taehunlee990803.png" width="100">
    </td>
  </tr>
  <tr height="35px">
    <td align="center" width="320px">
      <a> Image Enhancement <br> 3D Computer Vision </a>
    </td>
    <td align="center" width="320px">
      <a> Computer Vision <br> Computer Graphics <br> Multi-modal </a>
    </td>
    <td align="center" width="320px">
      <a> Automous Driving </a>
    </td>
  </tr>
</table>